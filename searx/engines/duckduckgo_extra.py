# SPDX-License-Identifier: AGPL-3.0-or-later
"""
DuckDuckGo Extra (images, videos, news)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
"""

import typing as t

import string
import random
from datetime import datetime
from urllib.parse import urlencode

import httpx
import lxml.html

# from searx.network import get
from searx import utils
from searx.engines.duckduckgo import fetch_traits  # pylint: disable=unused-import
from searx.engines import duckduckgo
from searx.result_types import EngineResults

if t.TYPE_CHECKING:
    from searx.extended_types import SXNG_Response
    from searx.search.processors import OnlineParams


# about
about = {
    "website": "https://duckduckgo.com/",
    "wikidata_id": "Q12805",
    "use_official_api": False,
    "require_api_key": False,
    "results": "JSON (site requires js to get images)",
}

# engine dependent config
categories = ["images", "web"]
ddg_category = "images"
"""The category must be any of ``images``, ``videos`` and ``news``
"""
paging = True
safesearch = True
send_accept_language_header = True

safesearch_cookies = {0: "-2", 1: None, 2: "1"}
safesearch_args = {0: "1", 1: None, 2: "1"}

search_path_map = {"images": "i", "videos": "v", "news": "news"}


def setup(engine_settings: dict[str, t.Any]) -> bool:  # pylint: disable=unused-argument
    return duckduckgo.setup(engine_settings=engine_settings)


def request_vqd_from_intro(query: str, params: "OnlineParams") -> str:
    # https://duckduckgo.com/?origin=funnel_home_website&t=h_&ia=images&iax=images&q={quote_plus(query)}
    resp = httpx.get(
        url=f"https://html.duckduckgo.com/html?q={query}",
        timeout=2,
        headers=params["headers"],
        # cookies=params["cookies"],   # FIXME ???
    )

    value: str = ""
    if resp.status_code >= 200 and resp.status_code <= 300:
        doc: lxml.html.HtmlElement = lxml.html.fromstring(resp.text)
        _val = doc.xpath("//input[@name='vqd']/@value")
        if _val:
            value = _val[0]

    if value:
        logger.debug("vqd value from duckduckgo.com request: '%s'", value)
    else:
        logger.error("vqd: can't parse value from ddg response (return empty string)")

    return value


def request(query: str, params: "OnlineParams") -> None:

    # FIXME: doesn't work yet .. an analysis is currently being carried out in
    # the SideCar in the ddg.py module.

    ##################################

    eng_region: str = traits.get_region(params["searxng_locale"], traits.all_locale)  # type: ignore
    eng_lang = duckduckgo.get_ddg_lang(traits, params["searxng_locale"])

    # headers ?!!?

    params["headers"]["Accept-Encoding"] = "gzip, deflate, bz"

    # The https://duckduckgo.com/i.js script and the other scripts on DDG
    # seem to have a special bot protection:
    #
    # - only well known UA headers are allowed to pass bot protection
    #
    # - The UA headers generated by SearXNG don’t work; apparently, the UA
    #   header always has to be the same (hard-coded)... but I don’t know the
    #   exact details yet.

    x = "".join(random.choice(string.digits) for _ in range(7))
    user_agent = f"Ling Long TV App ({x})"

    params["headers"]["User-Agent"] = user_agent
    logger.debug("XXXXXXXXX generic User-Agent is '%s'", user_agent)

    # cookies / used for user preferences

    params["cookies"]["kl"] = eng_region
    params["cookies"]["ad"] = eng_lang  # zh_CN
    params["cookies"]["ah"] = eng_region  # "us-en,de-de"
    params["cookies"]["l"] = eng_region  # "hk-tzh"

    safe_search = safesearch_cookies.get(params["safesearch"])
    if safe_search is not None:
        params["cookies"]["p"] = safe_search  # "-2", "1"
    logger.debug("cookies: %s", params["cookies"])

    vqd = duckduckgo.get_vqd(query=query)
    # Do we need to load the intro page first?
    if not vqd:
        # vqd is required to request other pages after the first one
        if params["pageno"] == 1:
            vqd = request_vqd_from_intro(query=query, params=params)
        if vqd:
            duckduckgo.set_vqd(query=query, digest=vqd)
        else:
            logger.error("while fetching intro page: no value for vqd")
            params["url"] = None
            return

    # arguments for the XMLHttpRequest

    args: dict[str, str | int] = {
        "o": "json",
        "q": query,
        "l": "de-de",  # FIXME
        "vqd": vqd,
        "p": 1,  # FIXME
        "ct": "DE",  # FIXME
        "bpia": 1,
    }

    # FIXME ..
    # if safe_search is not None:
    #     args["p"] = safe_search  # "-1", "1"
    # if params["pageno"] > 1:
    #     args["s"] = (params["pageno"] - 1) * 100

    params["url"] = f"https://duckduckgo.com/{search_path_map[ddg_category]}.js?{urlencode(args)}"

    # resp = httpx.get(
    #     url=params["url"],
    #     timeout=2,
    #     headers=params["headers"],
    #     cookies=params["cookies"],
    # )
    # pdb.set_trace()
    # resp.text


def _image_result(result: dict[str, t.Any]) -> dict[str, t.Any]:
    return {
        "template": "images.html",
        "url": result["url"],
        "title": result["title"],
        "content": "",
        "thumbnail_src": result["thumbnail"],
        "img_src": result["image"],
        "resolution": "%s x %s" % (result["width"], result["height"]),
        "source": result["source"],
    }


def _video_result(result: dict[str, t.Any]) -> dict[str, t.Any]:
    return {
        "template": "videos.html",
        "url": result["content"],
        "title": result["title"],
        "content": result["description"],
        "thumbnail": result["images"].get("small") or result["images"].get("medium"),
        "iframe_src": utils.get_embeded_stream_url(result["content"]),
        "source": result["provider"],
        "length": result["duration"],
        "metadata": result.get("uploader"),
    }


def _news_result(result: dict[str, t.Any]) -> dict[str, t.Any]:
    return {
        "url": result["url"],
        "title": result["title"],
        "content": utils.html_to_text(result["excerpt"]),
        "source": result["source"],
        "publishedDate": datetime.fromtimestamp(result["date"]),
    }


def response(resp: "SXNG_Response") -> EngineResults:
    res = EngineResults()
    try:
        res_json: dict[str, t.Any] = resp.json()
    except Exception as exc:
        raise
        # FIXME
        # pdb.set_trace()
        # return res

    for result in res_json["results"]:
        if ddg_category == "images":
            res.add(res.types.LegacyResult(**_image_result(result)))
        elif ddg_category == "videos":
            res.add(res.types.LegacyResult(**_video_result(result)))
        elif ddg_category == "news":
            res.add(res.types.MainResult(**_news_result(result)))
        else:
            raise ValueError(f"Invalid duckduckgo category: {ddg_category}")

    return res
